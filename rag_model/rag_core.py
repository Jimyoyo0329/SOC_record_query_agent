import os
import re
from typing import List
from sqlalchemy import inspect  
from openai import OpenAI
from langchain_community.utilities.sql_database import SQLDatabase
from langchain.chains import create_sql_query_chain
from langchain_chroma import Chroma
from langchain.chat_models import ChatOpenAI
from rag_model.embedding_utils import MyEmbedding
from langchain.chains.llm import LLMChain
from langchain_core.prompts import PromptTemplate

# ==== è¨­å®š ====
CHROMA_PATH = os.path.abspath("data2")
SQLITE_PATH = "sqlite:///SOC.db"
### å¦‚æœè¦å…¬é–‹è¦è¨˜å¾—æŠŠkey æ”¾åˆ°ç’°å¢ƒè®Šæ•¸
OPENAI_API_KEY = "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"
TOP_K = 4

# ==== åˆå§‹åŒ– ====
client = OpenAI(api_key=OPENAI_API_KEY)
llm = ChatOpenAI(model_name="gpt-4o", temperature=0, openai_api_key=OPENAI_API_KEY)
embedding = MyEmbedding()
vectorstore = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding)
sql_db = SQLDatabase.from_uri(SQLITE_PATH)

# ==== å–å¾—æ¬„ä½åç¨± ====
def get_column_names(db: SQLDatabase, table_name: str) -> List[str]:
    inspector = inspect(db._engine)
    columns = inspector.get_columns(table_name)
    return [col["name"] for col in columns]

# ==== SQL Prompt ====
sql_prompt = PromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä½è³‡å®‰è³‡æ–™åº«åˆ†æå¸«ï¼Œè«‹æ ¹æ“šä½¿ç”¨è€…å•é¡Œç”¢å‡º SQLite æŸ¥è©¢èªæ³•ã€‚
âš ï¸ è¦å‰‡ï¼š
1. åªèƒ½ä½¿ç”¨SELECTï¼Œä¸è¦ä½¿ç”¨å…¶ä»–èªæ³•ã€‚ã€‚
2. è‹¥ä½¿ç”¨è€…æœ‰æ˜ç¢ºæŒ‡å®šæ¬„ä½åç¨±ï¼Œè«‹åªæŸ¥è©¢é‚£äº›æ¬„ä½ã€‚
3. è«‹ä½¿ç”¨ SQLite èªæ³•ã€‚
4. åƒ…å›å‚³ SQL æŸ¥è©¢èªæ³•ï¼Œä¸è¦åŠ ä¸Šèªªæ˜æˆ–æ ¼å¼æ¨™è¨˜ã€‚
                                          
ä½¿ç”¨è€…å•é¡Œï¼š{question}
è³‡æ–™åº«çµæ§‹ï¼š
{schema}

è«‹ç”¢å‡ºæŸ¥è©¢èªæ³•ï¼š
""")

schema = sql_db.get_table_info()
sql_chain = LLMChain(llm=llm, prompt=sql_prompt)

# ==== æ¸…ç† SQL æŸ¥è©¢ ====
def clean_sql_query(raw_sql: str) -> str:
    raw_sql = raw_sql.strip()
    raw_sql = re.sub(r"^```(?:sqlite|sql)?\s*", "", raw_sql, flags=re.IGNORECASE)
    raw_sql = re.sub(r"\s*```$", "", raw_sql, flags=re.IGNORECASE)
    raw_sql = re.sub(r"^SQLQuery[:ï¼š]\s*", "", raw_sql, flags=re.IGNORECASE)
    raw_sql = raw_sql.splitlines()[0].strip()
    if not raw_sql.endswith(";"):
        raw_sql += ";"
    return raw_sql

# ==== ç”¢å‡ºæ‘˜è¦èˆ‡ç•°åŒæ¯”è¼ƒ ====
def summarize_rows(rows: List[tuple], columns: List[str], user_query: str):
    summaries = []
    for idx, row in enumerate(rows, 1):
        metadata = dict(zip(columns, row)) if columns else {f"col{i}": v for i, v in enumerate(row)}
        raw_info = "\n".join([f"- {k}: {v if v else 'ç„¡è³‡æ–™'}" for k, v in metadata.items()])
        user_prompt = f"""
        ã€ç¬¬ {idx} ç­†äº‹ä»¶æ‘˜è¦ã€‘

        ã€ä½¿ç”¨è€…å•é¡Œã€‘
        {user_query}

        ã€äº‹ä»¶è³‡æ–™ã€‘
        {raw_info}

        è«‹ç”¢å‡ºçµæ§‹åŒ–æ‘˜è¦ï¼Œè®“å…§å®¹æ¸…æ™°æ˜“è®€ï¼Œä¸è¦åŠ å…¥å…¶ä»–èªªæ˜ã€‚
        """
        system_prompt = """
            ä½ æ˜¯ä¸€ä½è³‡å®‰åˆ†æå¸«ï¼Œè«‹æ ¹æ“šæä¾›çš„äº‹ä»¶è³‡æ–™ç”¢å‡ºæ¸…æ™°ä¸”çµæ§‹åŒ–çš„æ‘˜è¦å ±å‘Šã€‚  
            âš ï¸ è¦å‰‡ï¼š  
            1. æ ¹æ“šè³‡æ–™æ¬„ä½åç¨±åŠå…¶å°æ‡‰å€¼å‹•æ…‹ç”Ÿæˆæ‘˜è¦ï¼Œä¸è¦ç¡¬å¥—æ¬„ä½åç¨±ã€‚  
            2. æ¯ç­†äº‹ä»¶è«‹å‰ç½®æ¨™é¡Œï¼šã€ç¬¬ N ç­†äº‹ä»¶æ‘˜è¦ã€‘ã€‚  
            3. è¼¸å‡ºçµæœç²¾ç°¡è¶Šå¥½ï¼Œé¿å…å†—é•·æè¿°ã€‚
            4. è‹¥è³‡æ–™ä¸­åŒ…å«ã€Œnoteã€æˆ–é¡ä¼¼å‚™è¨»æ¬„ä½ï¼Œè«‹ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ç”¢ç”Ÿäº‹ä»¶èƒŒæ™¯èˆ‡äº‹ä»¶å¤§ç¶±ï¼š  
            ã€ç¬¬ N ç­†äº‹ä»¶æ‘˜è¦ã€‘  
            ### äº‹ä»¶èƒŒæ™¯
            - æ™‚é–“: ...ï¼ˆè‹¥æœ‰ï¼‰  
            - å‘Šè­¦åç¨±: ...ï¼ˆè‹¥æœ‰ï¼‰  
            - ä¾†æº IP: ...ï¼ˆè‹¥æœ‰ï¼‰  
            - ç›®çš„ IP: ...ï¼ˆè‹¥æœ‰ï¼‰  
            - ç›¸é—œç¶²åŸŸ: ...ï¼ˆè‹¥æœ‰ï¼‰  

            ### äº‹ä»¶å¤§ç¶±
            - è² è²¬äººå“¡æˆ–å–®ä½: ï¼ˆè‹¥å¾å‚™è¨»ä¸­å¯æå–ï¼‰
            - äº‹ä»¶æ¦‚è¿°: ï¼ˆæ‘˜å–å‚™è¨»çš„ä¸»è¦æè¿°ï¼‰
            - æª¢æŸ¥çµæœ: ï¼ˆè‹¥æœ‰ï¼‰
            - çµè«–: ï¼ˆæ ¹æ“šå‚™è¨»å…§å®¹åˆç†æ¨è«–ã€‚è‹¥å‚™è¨»æåŠå·²é—œé–‰ã€éæƒ¡æ„ã€å·¥ä½œé–‹ç™¼ç­‰æƒ…æ³ï¼Œå¯æå‡ºæ¨æ¸¬çµè«–ï¼›è‹¥ç„¡æ˜ç¢ºç·šç´¢ï¼Œè«‹çœç•¥ã€‚ï¼‰  

            5. è‹¥è³‡æ–™ä¸­æ²’æœ‰ã€Œnoteã€æˆ–é¡ä¼¼å‚™è¨»æ¬„ä½ï¼Œè«‹ç›´æ¥ä»¥ç°¡æ½”çš„æ¢åˆ—å¼æ ¼å¼åˆ—å‡ºæ‰€æœ‰æ¬„ä½åç¨±èˆ‡å…¶å°æ‡‰å€¼ï¼Œä¸ç”¨å¥—ç”¨äº‹ä»¶èƒŒæ™¯å’Œäº‹ä»¶å¤§ç¶±æ ¼å¼ã€‚


        """
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": [{"type": "text", "text": system_prompt}]},
                    {"role": "user", "content": [{"type": "text", "text": user_prompt}]}
                ],
                temperature=0.1,
                max_tokens=500
            )
            summary = response.choices[0].message.content.strip()
            summaries.append(summary)
        except Exception as e:
            summaries.append(f"âŒ ç¬¬ {idx} ç­†æ‘˜è¦å¤±æ•—ï¼š{e}")

    # æ¯”è¼ƒ
    if len(summaries) >= 2:
        summary_text = "\n".join([f"ç¬¬{i+1}ç­†ï¼š\n{s}" for i, s in enumerate(summaries)])
        comparison_prompt = f"""
        ã€ä½¿ç”¨è€…å•é¡Œã€‘
        {user_query}

        ã€äº‹ä»¶æ‘˜è¦ã€‘
        {summary_text}

        è«‹å”åŠ©æ¯”è¼ƒé€™äº›äº‹ä»¶çš„ç•°åŒï¼Œè¦å‰‡å¦‚ä¸‹ï¼š
        1. å…ˆå°‡å¤šç­†è³‡æ–™ç”¨è¡¨æ ¼æ–¹å¼å‘ˆç¾
        2. è«‹ç”¢å‡ºæ¢åˆ—å¼èªªæ˜
         - å…±åŒé»
         - ä¸åŒé»
        """
        try:
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": [{"type": "text", "text": "ä½ æ˜¯ä¸€ä½è³‡å®‰åˆ†æå¸«ï¼Œè«‹é‡å°å¤šç­†äº‹ä»¶é€²è¡Œæ¯”è¼ƒã€‚"}]},
                    {"role": "user", "content": [{"type": "text", "text": comparison_prompt}]}
                ],
                temperature=0.5,
                max_tokens=800
            )
            result = response.choices[0].message.content.strip()
            summaries.append(result)
        except Exception as e:
            summaries.append(f"âŒ äº‹ä»¶æ¯”è¼ƒå¤±æ•—ï¼š{e}")
    return summaries

# ==== å‘é‡æŸ¥è©¢ fallback ====
def vector_fallback_search(query: str) -> List[str]:
    docs = vectorstore.similarity_search(query, k=TOP_K)
    return [doc.page_content for doc in docs]

# ==== ä¸»æŸ¥è©¢æµç¨‹ ====
def dual_query(user_query: str):
    print(f"\nğŸ”§ ä½¿ç”¨è€…åŸå§‹æŸ¥è©¢èªå¥ï¼š\n{user_query}\n")

    try:
        raw_sql_result = sql_chain.invoke({"question": user_query, "schema": schema})
        raw_sql_query = raw_sql_result["text"]
        print(f"\nğŸ§  æ¸…ç†å‰çš„ SQL æŸ¥è©¢èªæ³•ï¼š\n{raw_sql_query}\n")
        sql_query = clean_sql_query(raw_sql_query)
        print(f"\nğŸ§  æ¸…ç†å¾Œçš„ SQL æŸ¥è©¢èªæ³•ï¼š\n{sql_query}\n") 

        result = sql_db.run(sql_query)
        print(f"\nğŸ“¦ SQL æŸ¥è©¢çµæœåŸå§‹è¼¸å‡ºï¼š\n{result}\n")

        if isinstance(result, str):
            try:
                result = eval(result)
                print("ğŸ“¦ SQL æŸ¥è©¢çµæœå·²è½‰æ›ç‚º list")
            except Exception as e:
                print("âš ï¸ SQL æŸ¥è©¢çµæœç„¡æ³•è§£æï¼š", e)
                raise ValueError("SQL æŸ¥è©¢ç„¡è³‡æ–™")

        if not isinstance(result, list) or not all(isinstance(row, tuple) for row in result):
            print("âš ï¸ SQL æŸ¥è©¢çµæœæ ¼å¼ç•°å¸¸ï¼š", result)
            raise ValueError("SQL æŸ¥è©¢ç„¡è³‡æ–™")

        print(f"\nâœ… æŸ¥è©¢æˆåŠŸï¼Œå…±å–å¾— {len(result)} ç­†è³‡æ–™ã€‚\n")

        # âœ… ä½¿ç”¨ SQLAlchemy inspector æŠ“æ¬„ä½åç¨±
        table_names = re.findall(r"FROM\s+([^\s;]+)", sql_query, flags=re.IGNORECASE)
        table_name = table_names[0] if table_names else None
        cols = get_column_names(sql_db, table_name) if table_name else []

        # âœ… è¼¸å‡ºæ¬„ä½èˆ‡ç¬¬ä¸€ç­†è³‡æ–™
        if result:
            print("ğŸ‘‰ æ¬„ä½:", cols)
            print("ğŸ‘‰ ç¬¬ä¸€ç­†è³‡æ–™:", result[0])
        else:
            print("ğŸ‘‰ æŸ¥ç„¡è³‡æ–™")

        summaries = summarize_rows(result, cols, user_query)
        if summaries:
            print("å·²å®Œæˆå¤§ç¶±")
            print(summaries)
        return "\n\n---\n\n".join(summaries)

    except Exception as e:
        print(f"\nâš ï¸ SQL æŸ¥è©¢å¤±æ•—ï¼š{e}\n")
        docs = vector_fallback_search(user_query)
        return docs if docs else ["âŒ æŸ¥ç„¡çµæœ"]

